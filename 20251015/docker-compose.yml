version: "3.9"

x-env: &env
  TZ: UTC

networks:
  core:
  camunda:

volumes:
  pgdata:
  redisdata:
  arangodata:
  chromadata:
  meili-data:
  langfuse-data:
  kafka-data:
  zookeeper-data:
  esdata:        # camunda
  keycloak-data: # camunda

services:

  # ---------- Datastores (lightweight) ----------
  postgres:
    image: postgis/postgis:16-3.4
    container_name: postgres
    environment:
      <<: *env
      POSTGRES_USER: ${POSTGRES_USER:-ai}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-ai}
      POSTGRES_DB: ${POSTGRES_DB:-ai_platform}
      POSTGRES_INITDB_ARGS: "--data-checksums"
    ports: ["5432:5432"]
    healthcheck:
      test: ["CMD-SHELL","pg_isready -U ${POSTGRES_USER:-ai} -d ${POSTGRES_DB:-ai_platform}"]
      interval: 10s
      timeout: 5s
      retries: 10
    volumes:
      - pgdata:/var/lib/postgresql/data
    networks: [core]

  redis:
    image: redis:7.2
    container_name: redis
    command: ["redis-server","--save","","--appendonly","no"]
    ports: ["6379:6379"]
    volumes: [ redisdata:/data ]
    networks: [core]

  arangodb:
    image: arangodb:3.11
    container_name: arangodb
    environment:
      <<: *env
      ARANGO_ROOT_PASSWORD: ${ARANGO_ROOT_PASSWORD:-rootpwd}
    ports: ["8529:8529"]
    volumes: [ arangodata:/var/lib/arangodb3 ]
    networks: [core]

  chroma:
    image: chromadb/chroma:latest
    container_name: chroma
    environment:
      <<: *env
      IS_PERSISTENT: "TRUE"
      PERSIST_DIRECTORY: /chroma-data
    ports: ["8000:8000"]
    volumes: [ chromadata:/chroma-data ]
    networks: [core]

  # Lightweight full-text search (lower RAM than OpenSearch)
  meilisearch:
    image: getmeili/meilisearch:v1.8
    container_name: meilisearch
    environment:
      <<: *env
      MEILI_NO_ANALYTICS: "true"
    ports: ["7700:7700"]
    volumes: [ meili-data:/meili_data ]
    networks: [core]

  # ---------- Kafka (bitnami, minimal heap) ----------
  zookeeper:
    image: bitnami/zookeeper:3.9
    container_name: zookeeper
    environment:
      <<: *env
      ALLOW_ANONYMOUS_LOGIN: "yes"
      ZOO_4LW_COMMANDS_WHITELIST: "*"
    ports: ["2181:2181"]
    volumes: [ zookeeper-data:/bitnami/zookeeper ]
    networks: [core]

  kafka:
    image: bitnami/kafka:3.7
    container_name: kafka
    environment:
      <<: *env
      KAFKA_CFG_NODE_ID: 0
      KAFKA_CFG_PROCESS_ROLES: controller,broker
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: "0@kafka:9093"
      KAFKA_CFG_LISTENERS: "PLAINTEXT://:9092,CONTROLLER://:9093"
      KAFKA_CFG_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092"
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT"
      KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_HEAP_OPTS: "-Xms256m -Xmx512m"
    depends_on: [zookeeper]
    ports: ["9092:9092"]
    volumes: [ kafka-data:/bitnami/kafka ]
    networks: [core]

  # ---------- Langfuse (LLM observability) ----------
  langfuse:
    image: ghcr.io/langfuse/langfuse:latest
    container_name: langfuse
    environment:
      <<: *env
      DATABASE_URL: postgresql://${POSTGRES_USER:-ai}:${POSTGRES_PASSWORD:-ai}@postgres:5432/${POSTGRES_DB:-ai_platform}
      NEXTAUTH_URL: ${LANGFUSE_NEXTAUTH_URL:-http://localhost:3000}
      NEXTAUTH_SECRET: ${LANGFUSE_NEXTAUTH_SECRET:-devsecret}
      SALT: ${LANGFUSE_SALT:-langsalt}
      ENCRYPTION_KEY: ${LANGFUSE_ENCRYPTION_KEY:-00000000000000000000000000000000}
      TELEMETRY: "false"
      LANGFUSE_PUBLIC_KEY: ${LANGFUSE_PUBLIC_KEY:-public_dev}
      LANGFUSE_SECRET_KEY: ${LANGFUSE_SECRET_KEY:-secret_dev}
    depends_on:
      postgres:
        condition: service_healthy
    ports: ["3000:3000"]
    networks: [core]

  # ---------- Spring Boot app (Gradle) ----------
  server:
    build:
      context: ./server
      dockerfile: Dockerfile
    container_name: ai-server
    environment:
      <<: *env
      SPRING_PROFILES_ACTIVE: docker
      DB_URL: jdbc:postgresql://postgres:5432/${POSTGRES_DB:-ai_platform}
      DB_USER: ${POSTGRES_USER:-ai}
      DB_PASS: ${POSTGRES_PASSWORD:-ai}
      REDIS_URL: redis://redis:6379
      KAFKA_BOOTSTRAP: kafka:9092
      ARANGO_URL: http://arangodb:8529
      ARANGO_USER: root
      ARANGO_PASS: ${ARANGO_ROOT_PASSWORD:-rootpwd}
      CHROMA_URL: http://chroma:8000
      MEILI_URL: http://meilisearch:7700
      LANGFUSE_BASEURL: http://langfuse:3000
      LANGFUSE_PUBLIC_KEY: ${LANGFUSE_PUBLIC_KEY:-public_dev}
      LANGFUSE_SECRET_KEY: ${LANGFUSE_SECRET_KEY:-secret_dev}
    ports: ["8080:8080"]
    depends_on:
      postgres: { condition: service_healthy }
      redis: { condition: service_started }
      kafka: { condition: service_started }
      arangodb: { condition: service_started }
      chroma: { condition: service_started }
      meilisearch: { condition: service_started }
      langfuse: { condition: service_started }
    networks: [core]

  # ---------- Optional: local CPU LLM via Ollama ----------
  ollama:
    profiles: ["llm"]
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    volumes: [ "ollama:/root/.ollama" ]
    ports: ["11434:11434"]
    networks: [core]
    # after up: `docker exec -it ollama ollama pull phi3:mini` (smaller CPU model)

  # ---------- Optional: Camunda 8 WYSIWYG workflows (heavy) ----------
  elasticsearch:
    profiles: ["camunda"]
    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.4
    container_name: camunda-es
    environment:
      <<: *env
      discovery.type: single-node
      xpack.security.enabled: "false"
      ES_JAVA_OPTS: "-Xms512m -Xmx512m"
    ulimits:
      memlock: { soft: -1, hard: -1 }
      nofile: { soft: 65536, hard: 65536 }
    volumes: [ esdata:/usr/share/elasticsearch/data ]
    networks: [camunda]

  zeebe:
    profiles: ["camunda"]
    image: camunda/zeebe:8.6.3
    container_name: zeebe
    environment:
      <<: *env
      ZEEBE_BROKER_GATEWAY_NETWORK_HOST: 0.0.0.0
    ports: ["26500:26500"]
    depends_on: [elasticsearch]
    networks: [camunda]

  operate:
    profiles: ["camunda"]
    image: camunda/operate:8.6.3
    container_name: operate
    environment:
      <<: *env
      CAMUNDA_OPERATE_ELASTICSEARCH_URL: http://elasticsearch:9200
      CAMUNDA_OPERATE_ZEEBE_GATEWAYADDRESS: zeebe:26500
    ports: ["8081:8080"]
    depends_on: [zeebe, elasticsearch]
    networks: [camunda]

  tasklist:
    profiles: ["camunda"]
    image: camunda/tasklist:8.6.3
    container_name: tasklist
    environment:
      <<: *env
      CAMUNDA_TASKLIST_ELASTICSEARCH_URL: http://elasticsearch:9200
      CAMUNDA_TASKLIST_ZEEBE_GATEWAYADDRESS: zeebe:26500
    ports: ["8082:8080"]
    depends_on: [zeebe, elasticsearch]
    networks: [camunda]

  keycloak:
    profiles: ["camunda"]
    image: quay.io/keycloak/keycloak:24.0.5
    container_name: keycloak
    command: ["start-dev","--http-port=8080"]
    environment:
      <<: *env
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
    ports: ["8090:8080"]
    volumes: [ keycloak-data:/opt/keycloak/data ]
    networks: [camunda]

volumes:
  ollama:
